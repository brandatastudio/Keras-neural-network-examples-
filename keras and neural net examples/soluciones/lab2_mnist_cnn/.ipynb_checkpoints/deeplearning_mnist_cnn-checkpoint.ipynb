{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "# Lab assignment: classifying digits with Convolutional Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "<img src=\"img/lenet.png\" style=\"width:900px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "In this assignment we come back to the the problem of recognizing handwritten digits, this time using Convolutional Neural Networks. We will see how this architecture allows us to attain higher accuracy rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "## Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "Throughout this notebook you will find empty cells that you will need to fill with your own code. Follow the instructions in the notebook and pay special attention to the following symbols.\n",
    "\n",
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">You will need to solve a question by writing your own code or answer in the cell immediately below, or in a different file as instructed.</td></tr>\n",
    " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">This is a hint or useful observation that can help you solve this assignment. You are not expected to write any solution, but you should pay attention to them to understand the assignment.</td></tr>\n",
    " <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">This is an advanced and voluntary exercise that can help you gain a deeper knowledge into the topic. Good luck!</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid missing packages and compatibility issues you should run this notebook under one of the [recommended Deep Learning environment files](https://github.com/albarji/teaching-environments/tree/master/deeplearning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will embed any plots into the notebook instead of generating a new window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, if you need any help on the usage of a Python function you can place the writing cursor over its name and press Caps+Shift to produce a pop-out with related documentation. This will only work inside code cells. \n",
    "\n",
    "Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Load and prepared the data as you did in the previous notebook. Make sure to normalize the pixel values, and encode the outputs a one-hot vectors.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train_norm = X_train.astype('float32') / 255\n",
    "X_test_norm = X_test.astype('float32') / 255\n",
    "Y_train = np_utils.to_categorical(y_train, 10) # We have 10 classes to codify\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need the following keras classes, which you already used in the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further improve on this image recognition problem we need network layers that do consider the data as images, and take into account closeness of pixels to make decisions instead of just throwing all pixel data into a fully connected network and expect intelligence to emerge from chaos. **Convolutional** and **Pooling** layers are the best way to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting the data as tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While for the perceptrons above we vectorized the data to fit into the perceptron framework, for convolutional networks we will need to shape the data in the form of a **4-dimensional tensor**. The dimensions of such tensor represent the following:\n",
    "* Image index (e.g. 3th image in the dataset)\n",
    "* Row index\n",
    "* Column index\n",
    "* Channel index (e.g. colour channel in colored images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again make use of the reshape function to perform this transformation. We have 60000 images in our training set, and those images have 28 rows x 28 columns. Since these images are grayscale, the channel dimension only contains one channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintensor = X_train_norm.reshape(60000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Repeat the transformation for the test data. Save the resulting tensor in a variable named *testtensor*.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "testtensor = X_test_norm.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and pooling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When defining a convolutional network, Convolution and Pooling layers work together. The most popular way of using these layers is in the following pattern:\n",
    "* A Convolution layer with rectified linear activations\n",
    "* A Pooling layer\n",
    "* Dropout (if regularization wants to be enforced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can thus define a minimal convolutional network as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "kernel_size = 3 # Size of the kernel for the convolution layers\n",
    "pool_size = 2 # Size of the pooling region for the pooling layers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, # Number convolution channels to generate\n",
    "                        (kernel_size, kernel_size), # Size of convolution kernels\n",
    "                        padding='valid', # Strategy to deal with borders\n",
    "                        input_shape=(img_rows, img_cols, 1))) # Size = image rows x image columns x channels\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an issue, though: at some point we need to transform the tensor data into a vector, as the output of the network should be a vector of 10 values, representing class probabilities. We can do this by using a **Flatten** layer. Then we can add a standard Dense layer to produce the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Flatten\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Compile the defined network, choosing \"adam\" as the optimization algorithm, and train it with the data. Use the tensor data you prepared above, not the vectorized data. Then measure the accuracy over the test data. Have the Convolution and MaxPooling helped?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 4s - loss: 0.3806 - acc: 0.8926\n",
      "Epoch 2/20\n",
      " - 2s - loss: 0.1482 - acc: 0.9574\n",
      "Epoch 3/20\n",
      " - 3s - loss: 0.1063 - acc: 0.9696\n",
      "Epoch 4/20\n",
      " - 3s - loss: 0.0871 - acc: 0.9749\n",
      "Epoch 5/20\n",
      " - 3s - loss: 0.0780 - acc: 0.9771\n",
      "Epoch 6/20\n",
      " - 3s - loss: 0.0702 - acc: 0.9786\n",
      "Epoch 7/20\n",
      " - 3s - loss: 0.0639 - acc: 0.9809\n",
      "Epoch 8/20\n",
      " - 3s - loss: 0.0603 - acc: 0.9820\n",
      "Epoch 9/20\n",
      " - 2s - loss: 0.0549 - acc: 0.9836\n",
      "Epoch 10/20\n",
      " - 2s - loss: 0.0541 - acc: 0.9834\n",
      "Epoch 11/20\n",
      " - 2s - loss: 0.0495 - acc: 0.9847\n",
      "Epoch 12/20\n",
      " - 2s - loss: 0.0483 - acc: 0.9845\n",
      "Epoch 13/20\n",
      " - 3s - loss: 0.0449 - acc: 0.9858\n",
      "Epoch 14/20\n",
      " - 3s - loss: 0.0425 - acc: 0.9870\n",
      "Epoch 15/20\n",
      " - 3s - loss: 0.0396 - acc: 0.9876\n",
      "Epoch 16/20\n",
      " - 3s - loss: 0.0390 - acc: 0.9874\n",
      "Epoch 17/20\n",
      " - 3s - loss: 0.0362 - acc: 0.9884\n",
      "Epoch 18/20\n",
      " - 3s - loss: 0.0365 - acc: 0.9883\n",
      "Epoch 19/20\n",
      " - 3s - loss: 0.0329 - acc: 0.9897\n",
      "Epoch 20/20\n",
      " - 3s - loss: 0.0328 - acc: 0.9894\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "Test loss 0.04626866220661904\n",
      "Test accuracy 0.9851\n"
     ]
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "model.fit(\n",
    "    traintensor, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")\n",
    "score = model.evaluate(testtensor, Y_test)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Build and train a convolutional network with the following layers:\n",
    "<ul>\n",
    "     <li>A Convolution layer of 32 channels, kernel size 3 and rectified linear activation</li>\n",
    "     <li>Another Convolution layer of 32 channels, kernel size 3 and rectified linear activation</li>\n",
    "     <li>A MaxPooling layer of size 2</li>\n",
    "     <li>A 25% Dropout</li>\n",
    "     <li>A Flatten layer</li>\n",
    "     <li>A Dense layer with 128 units and rectified linear activation</li>\n",
    "     <li>A 50% Dropout</li>\n",
    "     <li>An output Dense layer with softmax activation</li>\n",
    "</ul>\n",
    "Has the added complexity improved the accuracy results?    \n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.2782 - acc: 0.9150\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0934 - acc: 0.9721\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.0715 - acc: 0.9784\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 102us/step - loss: 0.0604 - acc: 0.9820\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0516 - acc: 0.9842\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0444 - acc: 0.9863\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0396 - acc: 0.9877\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0367 - acc: 0.9882\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0337 - acc: 0.9890\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0296 - acc: 0.9905\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0298 - acc: 0.9903\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 6s 95us/step - loss: 0.0282 - acc: 0.9908\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.0250 - acc: 0.9911\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0233 - acc: 0.9924\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0231 - acc: 0.9924\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.0216 - acc: 0.9932\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0197 - acc: 0.9939\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0191 - acc: 0.9939\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0192 - acc: 0.9940\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.0186 - acc: 0.9938\n",
      "10000/10000 [==============================] - 1s 59us/step\n",
      "Test loss 0.0326757088860727\n",
      "Test accuracy 0.9915\n"
     ]
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "kernel_size = 3 # Size of the kernel for the convolution layers\n",
    "pool_size = 2 # Size of the pooling region for the pooling layers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, # Number convolution channels to generate\n",
    "                        (kernel_size, kernel_size),\n",
    "                        padding='valid',\n",
    "                        input_shape=(img_rows, img_cols, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, (kernel_size, kernel_size)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "model.fit(\n",
    "    traintensor, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=1 # Level of verbosity of the log messages\n",
    ")\n",
    "score = model.evaluate(testtensor, Y_test)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=http://yann.lecun.com/exdb/lenet/>LeNet</a> is a particular convolutional neural network definition that has proven to be quite effective. As a final exercise we will build this network and try it on our digits problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Build and train a LeNet network, which is defined by the following layers:\n",
    "<ul>\n",
    "     <li>A Convolution layer of 20 channels, kernel size 5 and rectified linear activation</li>\n",
    "     <li>A MaxPooling layer of size 2 and stride 2 (check <a href=\"https://keras.io/layers/pooling/\">the docs</a>)</li>\n",
    "     <li>A 25% Dropout</li>\n",
    "     <li>A Convolution layer of 50 channels, kernel size 5 and rectified linear activation</li>\n",
    "     <li>A MaxPooling layer of size 2 and stride 2 (check <a href=\"https://keras.io/layers/pooling/\">the docs</a>)</li>\n",
    "     <li>A 25% Dropout</li>\n",
    "     <li>A Flatten layer</li>\n",
    "     <li>A Dense layer with 500 units and rectified linear activation</li>\n",
    "     <li>A 50% Dropout</li>\n",
    "     <li>An output Dense layer with softmax activation</li>\n",
    "</ul>\n",
    "Is this the best network so far for the problem?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.2699 - acc: 0.9143\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.0838 - acc: 0.9745\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0628 - acc: 0.9805\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0510 - acc: 0.9838\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0435 - acc: 0.9868\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0392 - acc: 0.9871\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.0352 - acc: 0.9888\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.0326 - acc: 0.9898\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0294 - acc: 0.9907\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.0272 - acc: 0.9912\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.0259 - acc: 0.9916\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0246 - acc: 0.9920\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.0236 - acc: 0.9926\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0230 - acc: 0.9927\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0216 - acc: 0.9933\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0207 - acc: 0.9933\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0194 - acc: 0.9936\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0173 - acc: 0.9944\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0187 - acc: 0.9940\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0160 - acc: 0.9950\n",
      "10000/10000 [==============================] - 1s 52us/step\n",
      "Test loss 0.01650850636700352\n",
      "Test accuracy 0.9943\n"
     ]
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(20, (5, 5),\n",
    "                        padding='valid',\n",
    "                        input_shape=(img_rows, img_cols, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Convolution2D(50, (5, 5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "model.fit(\n",
    "    traintensor, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=1 # Level of verbosity of the log messages\n",
    ")\n",
    "score = model.evaluate(testtensor, Y_test)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.<br>\n",
    "                          THIS IS THE END OF THE ASSIGNMENT<br>\n",
    "~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.<br>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus rounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Rebuild the LeNet network with a larger number of training epochs. What is the best test error you can achieve?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "If your PC has a CUDA-compatible GPU card you can take advantage of it to significanly accelerate training times. You are encouraged to configure Keras to make use of your GPU.\n",
    " </td></tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
