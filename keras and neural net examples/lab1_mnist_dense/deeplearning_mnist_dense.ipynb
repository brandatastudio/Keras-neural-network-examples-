{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "# Lab assignment: classifying digits with dense networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "<img src=\"img/mnist.jpeg\" style=\"width:480px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "In this assignment we will face the problem of recognizing handwritten digits. We will use this as a benchmark to try different dense neural network architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "## Guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "Throughout this notebook you will find empty cells that you will need to fill with your own code. Follow the instructions in the notebook and pay special attention to the following symbols.\n",
    "\n",
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">You will need to solve a question by writing your own code or answer in the cell immediately below, or in a different file as instructed.</td></tr>\n",
    " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">This is a hint or useful observation that can help you solve this assignment. You are not expected to write any solution, but you should pay attention to them to understand the assignment.</td></tr>\n",
    " <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">This is an advanced and voluntary exercise that can help you gain a deeper knowledge into the topic. Good luck!</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid missing packages and compatibility issues you should run this notebook under one of the [recommended Deep Learning environment files](https://github.com/albarji/teaching-environments/tree/master/deeplearning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will embed any plots into the notebook instead of generating a new window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, if you need any help on the usage of a Python function you can place the writing cursor over its name and press Caps+Shift to produce a pop-out with related documentation. This will only work inside code cells. \n",
    "\n",
    "Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Keras library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we will make use of the <a href=\"http://keras.io/\">keras</a> Deep Learning library for Python. This library allows building several kinds of shallow and deep networks, following either a sequential or a graph architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The handwritten digits recognition problem we will face is already included as a testbed in keras. Loading it only requires invoking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loaded **X variables** are made up of the handwritten digits to classify, while the **y variables** contain the labels of the corresponding X images, telling the digits such images represent. We will use the **train** data to build our neural network, while we will use the **test** data to measure the performance of such network on an independent dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check how many images we have for training and testing as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we can take a look at the shape, width and height in pixels, of an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the images we are working with by means of using the matplotlib library. Here we are taking the first training image and painting it with a grayscale colormap. Also we are printing the corresponding class value, to ensure the labeling of the digit is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit class: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], 'gray')\n",
    "print(\"Digit class:\", y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Use the cell below to plot some other image in the training dataset, along with its corresponding digit class number. Can you find any hard to identify digit?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit class: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "plt.imshow(X_train[10], 'gray')\n",
    "print(\"Digit class:\", y_train[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting building networks we should always normalize our data. This usually means substracting the mean from each variable and then dividing by the standard deviation. However in grayscale images like the ones we are working with all variables represent pixel intensities, and are bound to integers in the range [0, 255]. We can thus perform a simple initialization by just compressing this range to [0, 1]. We should also transform the data to real numbers (float) while performing this operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = X_train.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Perform the same normalization for the test data\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "X_test_norm = X_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the outputs, normalization as such is not required, but we should change the class encoding to something more akin to neural networks. Instead of having a single integer ranging [0,9] to encode the different classes, we will use a <a href=\"https://en.wikipedia.org/wiki/One-hot\">one-hot vector encoding</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "Y_train = np_utils.to_categorical(y_train, 10) # We have 10 classes to codify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the transformation was correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Repeat the same encoding for the classes of the test data\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start trying to solve the problem with the simplest neural network: a Perceptron. This means a neural network with no hidden layers, just some weights going from input to output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a network in Keras begins by choosing the type of architecture. We can either decide to build a **Sequential** network, where each layer is followed by another one in a chain, or a **Graph** network, where divergences and loops of layers can take place. In this practice we will restrict ourselves to the Sequential architecture. We can initialize a Sequential network with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the network has been initialized this way, we just need to iteratively add the desired layers. For the perceptron network we only require a \"classic\" layer of weights from input to output. Such layer is name **Dense** in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually creating a dense layer only involves specifying the number of outputs units of such layer. But since this will be the first layer in the network we also need to specify the number of inputs. Our inputs are images of 28x28 pixels, which makes 784 input values. As for the outputs, we have 10 classes in our problem, so that makes 10 output units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "denselayer = Dense(10, input_dim=784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add the layer to network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(denselayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we have declared the layer of weights from inputs to outputs. Since we are facing a classification problem we should also add an activation function to the output units that enforces the output values to the range [0,1]. We will choose a softmax activation for doing so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Activation\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this the definition of our network is completed. We can get a text description of the network by calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the network architecture the next step involves compiling the network. Compilation is an automatic process that transforms the network definition into an equivalent symbolic formulation for which derivatives can be computed, thus allowing learning through backpropagation. The only input required in this process is choosing the loss function the network should minimize, and the optimizer used for learning.\n",
    "\n",
    "For our current network we will use **categorical crossentropy** as the loss function, as it is suitable for multiclass classification problems. As for the optimizer, we will use **Stochastic Gradient Descent**. We will also include the **classification accuracy** as a metric to measure the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now almost ready to adjust the network parameters through training over our data. There is only one small detail left: our data is in the form of bidimensional images, while a perceptron only understands training patterns as one-dimensional vectors of data. We should then transform the data to vector form to input it into the network, something we can do with the **reshape** method of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainvectors = X_train_norm.reshape(60000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check now that our training data has become a matrix of 60000 training patterns (rows) and 784 variables (pixels) per pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainvectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Perform a similar transformation for the X_test data, saving the reshaped data into a variable named *testvectors*. Note that the number of pattens in the test data is different from the number of patterns in the training data.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "testvectors = X_test_norm.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can invoke the **fit** method of the network, which will perform the training process. It is done as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 1s - loss: 1.2823 - acc: 0.7000\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.7178 - acc: 0.8393\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.5892 - acc: 0.8585\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.5274 - acc: 0.8683\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.4898 - acc: 0.8749\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.4638 - acc: 0.8797\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.4446 - acc: 0.8831\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.4296 - acc: 0.8859\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.4175 - acc: 0.8880\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.4074 - acc: 0.8900\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.3989 - acc: 0.8923\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.3915 - acc: 0.8940\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.3851 - acc: 0.8955\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.3794 - acc: 0.8964\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.3744 - acc: 0.8977\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.3698 - acc: 0.8986\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.3657 - acc: 0.8993\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.3619 - acc: 0.9005\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.3584 - acc: 0.9011\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.3552 - acc: 0.9019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faf2f0c6828>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    trainvectors, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our neural network model is trained, we can obtain class predictions for the test set as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_classes(testvectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the predictions, if we take for instance the first test pattern, its image and predicted class are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real class 7 predicted class 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[0], 'gray')\n",
    "print(\"Real class\", y_test[0], \"predicted class\", preds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Compare the predicted and real classes for other images in the test set. Can you find any error?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real class 5 predicted class 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "import numpy as np\n",
    "(fails,) = np.where(y_test != preds)\n",
    "plt.imshow(X_test[fails[0]], 'gray')\n",
    "print(\"Real class\", y_test[fails[0]], \"predicted class\", preds[fails[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/exclamation.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "You can spot all the errors in an automated way by comparing *y_test* against *preds* and getting the indexes of the mismatching elements. The function <a href=\"http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.where.html\">np.where</a> might also help.\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An overall accuracy measure can also be obtained by means of the **evaluate** method of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 24us/step\n",
      "Test loss 0.3370292641460896\n",
      "Test accuracy 0.9091\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(testvectors, Y_test)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Do you think the level of accuracy obtained is good enough for a real application? Suppose that every time a single digit is misclasified a package might be sent to the wrong address, and ZIP codes in the USA are made of 9 digits. What is the probability of sending a package to a wrong address?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5758642113150745"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "1-score[1]**9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A potential way to attain further improvements might be to create a deeper network, by adding layers of hidden units. This is easy to do in Keras, just by defining a new architecture with several Dense layers. For example, to build a network with a hidden layer of 10 units with sigmoid activation we would write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 7,960\n",
      "Trainable params: 7,960\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Compile the defined network and train it with the data. Then measure the accuracy over the test data. Have you managed to get any improvement over the previous Perceptron model?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 1s - loss: 2.2143 - acc: 0.3226\n",
      "Epoch 2/20\n",
      " - 1s - loss: 1.9850 - acc: 0.5174\n",
      "Epoch 3/20\n",
      " - 1s - loss: 1.7961 - acc: 0.5781\n",
      "Epoch 4/20\n",
      " - 1s - loss: 1.6315 - acc: 0.6276\n",
      "Epoch 5/20\n",
      " - 1s - loss: 1.4908 - acc: 0.6678\n",
      "Epoch 6/20\n",
      " - 1s - loss: 1.3714 - acc: 0.6968\n",
      "Epoch 7/20\n",
      " - 1s - loss: 1.2696 - acc: 0.7228\n",
      "Epoch 8/20\n",
      " - 1s - loss: 1.1819 - acc: 0.7441\n",
      "Epoch 9/20\n",
      " - 1s - loss: 1.1056 - acc: 0.7615\n",
      "Epoch 10/20\n",
      " - 1s - loss: 1.0386 - acc: 0.7780\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.9793 - acc: 0.7936\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.9266 - acc: 0.8053\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.8795 - acc: 0.8168\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.8375 - acc: 0.8256\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.7998 - acc: 0.8340\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.7659 - acc: 0.8396\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.7353 - acc: 0.8454\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.7077 - acc: 0.8498\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.6827 - acc: 0.8537\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.6600 - acc: 0.8575\n",
      "10000/10000 [==============================] - 0s 32us/step\n",
      "Test loss 0.6425494316101075\n",
      "Test accuracy 0.8664\n"
     ]
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model.fit(\n",
    "    trainvectors, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")\n",
    "score = model.evaluate(testvectors, Y_test)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning the network design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the performance of the multilayer perceptron we will use the following:\n",
    "* Increase the number of hidden units\n",
    "* Use a better activation function: rectified linear\n",
    "* Use a better optimizer: adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This boils down to defining the network as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=784))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Compile the defined network, choosing \"adam\" as the optimization algorithm, and train it with the data. Then measure the accuracy over the test data. Did these changes give rise to better results?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 1s - loss: 0.3806 - acc: 0.8947\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.1775 - acc: 0.9492\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.1300 - acc: 0.9629\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.1023 - acc: 0.9705\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.0842 - acc: 0.9759\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.0703 - acc: 0.9798\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.0596 - acc: 0.9831\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.0514 - acc: 0.9851\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.0437 - acc: 0.9877\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.0383 - acc: 0.9891\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.0325 - acc: 0.9912\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.0288 - acc: 0.9921\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.0252 - acc: 0.9929\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.0214 - acc: 0.9945\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.0185 - acc: 0.9957\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.0167 - acc: 0.9959\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.0139 - acc: 0.9972\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.0132 - acc: 0.9970\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.0105 - acc: 0.9979\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.0092 - acc: 0.9984\n",
      "10000/10000 [==============================] - 0s 27us/step\n",
      "Test loss 0.08591945080713777\n",
      "Test accuracy 0.9775\n"
     ]
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(\n",
    "    trainvectors, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")\n",
    "score = model.evaluate(testvectors, Y_test)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Define a new network with two hidden layers, each of 512 hidden units with rectified linear activation. For the output use the softmax activation. Compile the defined network, choosing \"adam\" as the optimization algorithm, and train it with the data. Then measure the accuracy over the test data. How are you doing now?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 2s - loss: 0.2150 - acc: 0.9367\n",
      "Epoch 2/20\n",
      " - 2s - loss: 0.0768 - acc: 0.9760\n",
      "Epoch 3/20\n",
      " - 2s - loss: 0.0476 - acc: 0.9850\n",
      "Epoch 4/20\n",
      " - 2s - loss: 0.0354 - acc: 0.9888\n",
      "Epoch 5/20\n",
      " - 2s - loss: 0.0280 - acc: 0.9908\n",
      "Epoch 6/20\n",
      " - 2s - loss: 0.0206 - acc: 0.9933\n",
      "Epoch 7/20\n",
      " - 2s - loss: 0.0185 - acc: 0.9934\n",
      "Epoch 8/20\n",
      " - 2s - loss: 0.0162 - acc: 0.9949\n",
      "Epoch 9/20\n",
      " - 2s - loss: 0.0148 - acc: 0.9951\n",
      "Epoch 10/20\n",
      " - 2s - loss: 0.0140 - acc: 0.9950\n",
      "Epoch 11/20\n",
      " - 2s - loss: 0.0124 - acc: 0.9958\n",
      "Epoch 12/20\n",
      " - 2s - loss: 0.0089 - acc: 0.9972\n",
      "Epoch 13/20\n",
      " - 2s - loss: 0.0095 - acc: 0.9968\n",
      "Epoch 14/20\n",
      " - 2s - loss: 0.0135 - acc: 0.9956\n",
      "Epoch 15/20\n",
      " - 2s - loss: 0.0067 - acc: 0.9980\n",
      "Epoch 16/20\n",
      " - 2s - loss: 0.0122 - acc: 0.9962\n",
      "Epoch 17/20\n",
      " - 2s - loss: 0.0078 - acc: 0.9972\n",
      "Epoch 18/20\n",
      " - 2s - loss: 0.0071 - acc: 0.9979\n",
      "Epoch 19/20\n",
      " - 2s - loss: 0.0088 - acc: 0.9973\n",
      "Epoch 20/20\n",
      " - 2s - loss: 0.0081 - acc: 0.9971\n",
      "10000/10000 [==============================] - 0s 31us/step\n",
      "Test loss 0.09847309462003\n",
      "Test accuracy 0.9828\n"
     ]
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=784))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "model.fit(\n",
    "    trainvectors, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")\n",
    "score = model.evaluate(testvectors, Y_test)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization can help improve the performance of a network, specially when the number of network parameters becomes large and this leads to better performance in training data than in test data, which is to say, overfitting. One of the most simple and effective ways of doing so is by using **dropout**. In Keras dropout is imposed on the network by adding a **Dropout** layer. Such Dropout layer takes the outputs from the previous layer and randomly assigns $0$ values to some of them, so that the next layer only sees part of the outputs generated.\n",
    "\n",
    "For instance, to create a network with a hidden layer with a dropout of a 30% probability of dropping an output we would write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Dropout\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=784))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Define a new network with two hidden layers, each of 512 hidden units with rectified linear activation. After both hidden layers you should add a Dropout of 40%. For the output use the softmax activation. Compile the defined network, choosing \"adam\" as the optimization algorithm, and train it with the data. Then measure the accuracy over the test data. Has dropout helped?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 2s - loss: 0.3020 - acc: 0.9064\n",
      "Epoch 2/20\n",
      " - 2s - loss: 0.1362 - acc: 0.9589\n",
      "Epoch 3/20\n",
      " - 2s - loss: 0.1021 - acc: 0.9674\n",
      "Epoch 4/20\n",
      " - 2s - loss: 0.0829 - acc: 0.9737\n",
      "Epoch 5/20\n",
      " - 2s - loss: 0.0700 - acc: 0.9780\n",
      "Epoch 6/20\n",
      " - 2s - loss: 0.0648 - acc: 0.9793\n",
      "Epoch 7/20\n",
      " - 2s - loss: 0.0570 - acc: 0.9819\n",
      "Epoch 8/20\n",
      " - 2s - loss: 0.0535 - acc: 0.9826\n",
      "Epoch 9/20\n",
      " - 2s - loss: 0.0497 - acc: 0.9840\n",
      "Epoch 10/20\n",
      " - 2s - loss: 0.0479 - acc: 0.9846\n",
      "Epoch 11/20\n",
      " - 2s - loss: 0.0435 - acc: 0.9859\n",
      "Epoch 12/20\n",
      " - 2s - loss: 0.0424 - acc: 0.9859\n",
      "Epoch 13/20\n",
      " - 2s - loss: 0.0391 - acc: 0.9873\n",
      "Epoch 14/20\n",
      " - 2s - loss: 0.0364 - acc: 0.9883\n",
      "Epoch 15/20\n",
      " - 2s - loss: 0.0359 - acc: 0.9882\n",
      "Epoch 16/20\n",
      " - 2s - loss: 0.0336 - acc: 0.9896\n",
      "Epoch 17/20\n",
      " - 2s - loss: 0.0345 - acc: 0.9884\n",
      "Epoch 18/20\n",
      " - 2s - loss: 0.0318 - acc: 0.9898\n",
      "Epoch 19/20\n",
      " - 2s - loss: 0.0316 - acc: 0.9899\n",
      "Epoch 20/20\n",
      " - 2s - loss: 0.0292 - acc: 0.9905\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "Test loss 0.06187918934401387\n",
      "Test accuracy 0.9853\n"
     ]
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=784))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "model.fit(\n",
    "    trainvectors, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")\n",
    "score = model.evaluate(testvectors, Y_test)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/question.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "Try training a network with more hidden layers. Does the performance improve in any way by doing this?\n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 3s - loss: 0.3434 - acc: 0.8943\n",
      "Epoch 2/20\n",
      " - 2s - loss: 0.1514 - acc: 0.9541\n",
      "Epoch 3/20\n",
      " - 2s - loss: 0.1184 - acc: 0.9647\n",
      "Epoch 4/20\n",
      " - 2s - loss: 0.1009 - acc: 0.9693\n",
      "Epoch 5/20\n",
      " - 2s - loss: 0.0882 - acc: 0.9737\n",
      "Epoch 6/20\n",
      " - 2s - loss: 0.0794 - acc: 0.9761\n",
      "Epoch 7/20\n",
      " - 2s - loss: 0.0736 - acc: 0.9773\n",
      "Epoch 8/20\n",
      " - 2s - loss: 0.0665 - acc: 0.9802\n",
      "Epoch 9/20\n",
      " - 2s - loss: 0.0640 - acc: 0.9806\n",
      "Epoch 10/20\n",
      " - 2s - loss: 0.0587 - acc: 0.9816\n",
      "Epoch 11/20\n",
      " - 2s - loss: 0.0556 - acc: 0.9827\n",
      "Epoch 12/20\n",
      " - 2s - loss: 0.0526 - acc: 0.9832\n",
      "Epoch 13/20\n",
      " - 2s - loss: 0.0520 - acc: 0.9842\n",
      "Epoch 14/20\n",
      " - 2s - loss: 0.0481 - acc: 0.9849\n",
      "Epoch 15/20\n",
      " - 2s - loss: 0.0484 - acc: 0.9850\n",
      "Epoch 16/20\n",
      " - 2s - loss: 0.0424 - acc: 0.9869\n",
      "Epoch 17/20\n",
      " - 2s - loss: 0.0456 - acc: 0.9860\n",
      "Epoch 18/20\n",
      " - 2s - loss: 0.0432 - acc: 0.9869\n",
      "Epoch 19/20\n",
      " - 2s - loss: 0.0425 - acc: 0.9872\n",
      "Epoch 20/20\n",
      " - 2s - loss: 0.0401 - acc: 0.9879\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "Test loss 0.06058417483924432\n",
      "Test accuracy 0.9848\n"
     ]
    }
   ],
   "source": [
    "####### INSERT YOUR CODE HERE\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=784))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "model.fit(\n",
    "    trainvectors, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")\n",
    "score = model.evaluate(testvectors, Y_test)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.<br>\n",
    "                          THIS IS THE END OF THE ASSIGNMENT<br>\n",
    "~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.<br>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus rounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    " <tr><td width=\"80\"><img src=\"img/pro.png\" style=\"width:auto;height:auto\"></td><td style=\"text-align:left\">\n",
    "If your PC has a CUDA-compatible GPU card you can take advantage of it to significanly accelerate training times. You are encouraged to configure Keras to make use of your GPU.\n",
    " </td></tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
